{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88c1bbe8-cd17-4050-86b7-8498b253cb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.quantization import get_default_qconfig, prepare, convert, fuse_modules\n",
    "from torchvision import models, transforms, datasets\n",
    "from torch.utils.data import DataLoader, Subset, random_split\n",
    "# from Model.Schema import resModel\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "from torch.quantization import QuantStub, DeQuantStub\n",
    "import torchmetrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "135bb0b7-cddf-4f47-afc7-9c2d804622a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.quantized import FloatFunctional\n",
    "\n",
    "class QuantizedBasicBlock(nn.Module):\n",
    "    def __init__(self, basic_block):\n",
    "        super(QuantizedBasicBlock, self).__init__()\n",
    "        self.conv1 = basic_block.conv1\n",
    "        self.bn1 = basic_block.bn1\n",
    "        self.relu = basic_block.relu\n",
    "        self.conv2 = basic_block.conv2\n",
    "        self.bn2 = basic_block.bn2\n",
    "        self.downsample = basic_block.downsample\n",
    "        self.stride = basic_block.stride\n",
    "        self.add = FloatFunctional()\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "        out = self.add.add(out, identity)\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "class resModel(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(resModel, self).__init__()\n",
    "        self.model = models.resnet18(weights=\"IMAGENET1K_V1\")\n",
    "        self.model.fc = nn.Linear(self.model.fc.in_features, num_classes)\n",
    "\n",
    "        self.accuracy = torchmetrics.Accuracy(task=\"multiclass\", num_classes=num_classes)\n",
    "        self.precision = torchmetrics.Precision(task=\"multiclass\", average=\"macro\", num_classes=num_classes)\n",
    "        self.recall = torchmetrics.Recall(task=\"multiclass\", average=\"macro\", num_classes=num_classes)\n",
    "        self.f1score = torchmetrics.F1Score(task=\"multiclass\", num_classes=num_classes)\n",
    "\n",
    "        self.model.layer1 = nn.Sequential(\n",
    "            QuantizedBasicBlock(self.model.layer1[0]),\n",
    "            QuantizedBasicBlock(self.model.layer1[1])\n",
    "        )\n",
    "        self.model.layer2 = nn.Sequential(\n",
    "            QuantizedBasicBlock(self.model.layer2[0]),\n",
    "            QuantizedBasicBlock(self.model.layer2[1])\n",
    "        )\n",
    "        self.model.layer3 = nn.Sequential(\n",
    "            QuantizedBasicBlock(self.model.layer3[0]),\n",
    "            QuantizedBasicBlock(self.model.layer3[1])\n",
    "        )\n",
    "        self.model.layer4 = nn.Sequential(\n",
    "            QuantizedBasicBlock(self.model.layer4[0]),\n",
    "            QuantizedBasicBlock(self.model.layer4[1])\n",
    "        )\n",
    "        \n",
    "        self.quant = torch.quantization.QuantStub()\n",
    "        self.dequant = torch.quantization.DeQuantStub()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.quant(x)\n",
    "        x = self.model(x)\n",
    "        x = self.dequant(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f84911eb-c915-41a7-9840-6ec17ed4dbc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "resModel(\n",
       "  (model): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=512, out_features=70, bias=True)\n",
       "  )\n",
       "  (accuracy): MulticlassAccuracy()\n",
       "  (precision): MulticlassPrecision()\n",
       "  (recall): MulticlassRecall()\n",
       "  (f1score): MulticlassF1Score()\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = 70\n",
    "model = resModel(num_classes)\n",
    "model.load_state_dict(torch.load('Weights/model_13.pth'))\n",
    "model.eval()\n",
    "\n",
    "model_fp32 = resModel(num_classes)\n",
    "model_fp32.load_state_dict(torch.load('Weights/model_13.pth'))\n",
    "model_fp32.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1feb2ea3-fc4f-4582-b8aa-a564e1aa0532",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xnpen\\anaconda3\\envs\\ml_homework\\Lib\\site-packages\\torch\\ao\\quantization\\observer.py:220: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
      "  warnings.warn(\n",
      "Calibrating: 100%|█████████████████████████████████████████████████████████████████████| 25/25 [00:41<00:00,  1.68s/it]\n"
     ]
    }
   ],
   "source": [
    "def skip_add_quantization(m):\n",
    "    if isinstance(m, models.resnet.BasicBlock) and hasattr(m, 'downsample') and m.downsample is not None:\n",
    "        m.qconfig = None\n",
    "\n",
    "model.qconfig = torch.quantization.get_default_qconfig('fbgemm')\n",
    "model.apply(skip_add_quantization)\n",
    "\n",
    "model_prepared = prepare(model, inplace=True)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "full_dataset = datasets.ImageFolder(root='dataset/train', transform=transform)\n",
    "\n",
    "num_calibration = int(0.1 * len(full_dataset))\n",
    "num_rest = len(full_dataset) - num_calibration\n",
    "calibration_dataset, _ = random_split(full_dataset, [num_calibration, num_rest])\n",
    "\n",
    "calibration_loader = DataLoader(calibration_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "model_prepared.eval()\n",
    "with torch.no_grad():\n",
    "    for data, _ in tqdm(calibration_loader, desc=\"Calibrating\", leave=True):\n",
    "        data = data.to('cpu')\n",
    "        model_prepared(data)\n",
    "\n",
    "        \n",
    "model_prepared.to('cpu')\n",
    "\n",
    "model_quantized = convert(model_prepared, inplace=False)\n",
    "\n",
    "torch.save(model_quantized.state_dict(), 'Weights/model_quantized_13.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6ba39e5-d76c-4864-b5fc-4643e2aeccb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_transform = transforms.Compose([\n",
    "#     transforms.Resize((256, 256)),\n",
    "#     transforms.ToTensor()\n",
    "# ])\n",
    "\n",
    "# image_path = 'dataset/valid/American  Spaniel/07.jpg'\n",
    "# image = Image.open(image_path).convert('RGB')\n",
    "\n",
    "# image = test_transform(image).unsqueeze(0)\n",
    "\n",
    "\n",
    "# model_quantized.eval()\n",
    "\n",
    "# device = torch.device('cpu')\n",
    "# model_quantized.to(device)\n",
    "# image = image.to(device)\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     output = model_quantized(image)\n",
    "#     prediction = torch.argmax(output, dim=1)\n",
    "\n",
    "# print(prediction.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4566ec4c-db45-48c6-bdbc-60aeed5ae0d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "resModel(\n",
       "  (model): ResNet(\n",
       "    (conv1): QuantizedConv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), scale=0.10969597846269608, zero_point=52, padding=(3, 3), bias=False)\n",
       "    (bn1): QuantizedBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): QuantizedBasicBlock(\n",
       "        (conv1): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.19458085298538208, zero_point=78, padding=(1, 1), bias=False)\n",
       "        (bn1): QuantizedBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.07432597130537033, zero_point=77, padding=(1, 1), bias=False)\n",
       "        (bn2): QuantizedBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (add): QFunctional(\n",
       "          scale=0.06085054203867912, zero_point=49\n",
       "          (activation_post_process): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): QuantizedBasicBlock(\n",
       "        (conv1): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.16924694180488586, zero_point=67, padding=(1, 1), bias=False)\n",
       "        (bn1): QuantizedBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.0588177852332592, zero_point=66, padding=(1, 1), bias=False)\n",
       "        (bn2): QuantizedBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (add): QFunctional(\n",
       "          scale=0.07378915697336197, zero_point=57\n",
       "          (activation_post_process): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): QuantizedBasicBlock(\n",
       "        (conv1): QuantizedConv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), scale=0.1407773643732071, zero_point=72, padding=(1, 1), bias=False)\n",
       "        (bn1): QuantizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): QuantizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.04531305283308029, zero_point=75, padding=(1, 1), bias=False)\n",
       "        (bn2): QuantizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): QuantizedConv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), scale=0.04169765114784241, zero_point=64, bias=False)\n",
       "          (1): QuantizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (add): QFunctional(\n",
       "          scale=0.04987456277012825, zero_point=60\n",
       "          (activation_post_process): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): QuantizedBasicBlock(\n",
       "        (conv1): QuantizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.09174706041812897, zero_point=64, padding=(1, 1), bias=False)\n",
       "        (bn1): QuantizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): QuantizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.04469120502471924, zero_point=69, padding=(1, 1), bias=False)\n",
       "        (bn2): QuantizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (add): QFunctional(\n",
       "          scale=0.06190086156129837, zero_point=54\n",
       "          (activation_post_process): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): QuantizedBasicBlock(\n",
       "        (conv1): QuantizedConv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), scale=0.08752027153968811, zero_point=67, padding=(1, 1), bias=False)\n",
       "        (bn1): QuantizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.06572026759386063, zero_point=69, padding=(1, 1), bias=False)\n",
       "        (bn2): QuantizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): QuantizedConv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), scale=0.021001383662223816, zero_point=68, bias=False)\n",
       "          (1): QuantizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (add): QFunctional(\n",
       "          scale=0.049382664263248444, zero_point=62\n",
       "          (activation_post_process): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): QuantizedBasicBlock(\n",
       "        (conv1): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.12242832034826279, zero_point=63, padding=(1, 1), bias=False)\n",
       "        (bn1): QuantizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.06841541081666946, zero_point=74, padding=(1, 1), bias=False)\n",
       "        (bn2): QuantizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (add): QFunctional(\n",
       "          scale=0.05669757351279259, zero_point=66\n",
       "          (activation_post_process): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): QuantizedBasicBlock(\n",
       "        (conv1): QuantizedConv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), scale=0.08546537905931473, zero_point=70, padding=(1, 1), bias=False)\n",
       "        (bn1): QuantizedBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.04717102274298668, zero_point=67, padding=(1, 1), bias=False)\n",
       "        (bn2): QuantizedBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): QuantizedConv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), scale=0.02112920768558979, zero_point=63, bias=False)\n",
       "          (1): QuantizedBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (add): QFunctional(\n",
       "          scale=0.055251576006412506, zero_point=69\n",
       "          (activation_post_process): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): QuantizedBasicBlock(\n",
       "        (conv1): QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.15348514914512634, zero_point=72, padding=(1, 1), bias=False)\n",
       "        (bn1): QuantizedBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.09802272915840149, zero_point=49, padding=(1, 1), bias=False)\n",
       "        (bn2): QuantizedBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (add): QFunctional(\n",
       "          scale=0.276776522397995, zero_point=43\n",
       "          (activation_post_process): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): QuantizedLinear(in_features=512, out_features=70, scale=0.47415706515312195, zero_point=79, qscheme=torch.per_channel_affine)\n",
       "  )\n",
       "  (accuracy): MulticlassAccuracy()\n",
       "  (precision): MulticlassPrecision()\n",
       "  (recall): MulticlassRecall()\n",
       "  (f1score): MulticlassF1Score()\n",
       "  (quant): Quantize(scale=tensor([0.0079]), zero_point=tensor([0]), dtype=torch.quint8)\n",
       "  (dequant): DeQuantize()\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_quantized.eval()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2dd3b96c-01c9-4010-a791-81d71ace0bc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "resModel(\n",
       "  (model): ResNet(\n",
       "    (conv1): QuantizedConv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), scale=0.10969597846269608, zero_point=52, padding=(3, 3), bias=False)\n",
       "    (bn1): QuantizedBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): QuantizedBasicBlock(\n",
       "        (conv1): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.19458085298538208, zero_point=78, padding=(1, 1), bias=False)\n",
       "        (bn1): QuantizedBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.07432597130537033, zero_point=77, padding=(1, 1), bias=False)\n",
       "        (bn2): QuantizedBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (add): QFunctional(\n",
       "          scale=0.06085054203867912, zero_point=49\n",
       "          (activation_post_process): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): QuantizedBasicBlock(\n",
       "        (conv1): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.16924694180488586, zero_point=67, padding=(1, 1), bias=False)\n",
       "        (bn1): QuantizedBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.0588177852332592, zero_point=66, padding=(1, 1), bias=False)\n",
       "        (bn2): QuantizedBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (add): QFunctional(\n",
       "          scale=0.07378915697336197, zero_point=57\n",
       "          (activation_post_process): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): QuantizedBasicBlock(\n",
       "        (conv1): QuantizedConv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), scale=0.1407773643732071, zero_point=72, padding=(1, 1), bias=False)\n",
       "        (bn1): QuantizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): QuantizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.04531305283308029, zero_point=75, padding=(1, 1), bias=False)\n",
       "        (bn2): QuantizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): QuantizedConv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), scale=0.04169765114784241, zero_point=64, bias=False)\n",
       "          (1): QuantizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (add): QFunctional(\n",
       "          scale=0.04987456277012825, zero_point=60\n",
       "          (activation_post_process): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): QuantizedBasicBlock(\n",
       "        (conv1): QuantizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.09174706041812897, zero_point=64, padding=(1, 1), bias=False)\n",
       "        (bn1): QuantizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): QuantizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.04469120502471924, zero_point=69, padding=(1, 1), bias=False)\n",
       "        (bn2): QuantizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (add): QFunctional(\n",
       "          scale=0.06190086156129837, zero_point=54\n",
       "          (activation_post_process): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): QuantizedBasicBlock(\n",
       "        (conv1): QuantizedConv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), scale=0.08752027153968811, zero_point=67, padding=(1, 1), bias=False)\n",
       "        (bn1): QuantizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.06572026759386063, zero_point=69, padding=(1, 1), bias=False)\n",
       "        (bn2): QuantizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): QuantizedConv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), scale=0.021001383662223816, zero_point=68, bias=False)\n",
       "          (1): QuantizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (add): QFunctional(\n",
       "          scale=0.049382664263248444, zero_point=62\n",
       "          (activation_post_process): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): QuantizedBasicBlock(\n",
       "        (conv1): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.12242832034826279, zero_point=63, padding=(1, 1), bias=False)\n",
       "        (bn1): QuantizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.06841541081666946, zero_point=74, padding=(1, 1), bias=False)\n",
       "        (bn2): QuantizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (add): QFunctional(\n",
       "          scale=0.05669757351279259, zero_point=66\n",
       "          (activation_post_process): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): QuantizedBasicBlock(\n",
       "        (conv1): QuantizedConv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), scale=0.08546537905931473, zero_point=70, padding=(1, 1), bias=False)\n",
       "        (bn1): QuantizedBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.04717102274298668, zero_point=67, padding=(1, 1), bias=False)\n",
       "        (bn2): QuantizedBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): QuantizedConv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), scale=0.02112920768558979, zero_point=63, bias=False)\n",
       "          (1): QuantizedBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (add): QFunctional(\n",
       "          scale=0.055251576006412506, zero_point=69\n",
       "          (activation_post_process): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): QuantizedBasicBlock(\n",
       "        (conv1): QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.15348514914512634, zero_point=72, padding=(1, 1), bias=False)\n",
       "        (bn1): QuantizedBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.09802272915840149, zero_point=49, padding=(1, 1), bias=False)\n",
       "        (bn2): QuantizedBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (add): QFunctional(\n",
       "          scale=0.276776522397995, zero_point=43\n",
       "          (activation_post_process): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): QuantizedLinear(in_features=512, out_features=70, scale=0.47415706515312195, zero_point=79, qscheme=torch.per_channel_affine)\n",
       "  )\n",
       "  (accuracy): MulticlassAccuracy()\n",
       "  (precision): MulticlassPrecision()\n",
       "  (recall): MulticlassRecall()\n",
       "  (f1score): MulticlassF1Score()\n",
       "  (quant): Quantize(scale=tensor([0.0079]), zero_point=tensor([0]), dtype=torch.quint8)\n",
       "  (dequant): DeQuantize()\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from Model.Schema import resModel\n",
    "import wandb\n",
    "from tqdm import tqdm\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "test_dataset = datasets.ImageFolder(root='dataset/test', transform=test_transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "def test_model(model, test_loader, device):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in tqdm(test_loader, desc=\"Testing\", leave=True):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "\n",
    "            output = model(data)\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "    test_accuracy = 100 * correct / total\n",
    "    return test_accuracy\n",
    "\n",
    "device= torch.device('cpu')\n",
    "model_quantized.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ce8fe473-5937-4be8-8c21-d5b2aa5a8978",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|█████████████████████████████████████████████████████████████████████████| 11/11 [00:10<00:00,  1.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the static quantized model: 86.14285714285714%\n",
      "Time taken to test the static quantized model: 10.329203367233276 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|█████████████████████████████████████████████████████████████████████████| 11/11 [00:17<00:00,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the standard model: 86.42857142857143%\n",
      "Time taken to test the standard model: 17.2046480178833 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time_q = time.time()\n",
    "accuracy_q = test_model(model_quantized, test_loader, device)\n",
    "end_time_q = time.time()\n",
    "\n",
    "\n",
    "print(f\"Test Accuracy of the static quantized model: {accuracy_q}%\")\n",
    "print(f\"Time taken to test the static quantized model: {end_time_q - start_time_q} seconds\")\n",
    "\n",
    "\n",
    "\n",
    "start_time_s = time.time()\n",
    "accuracy_s = test_model(model_fp32, test_loader, device)\n",
    "end_time_s = time.time()\n",
    "\n",
    "print(f\"Test Accuracy of the standard model: {accuracy_s}%\")\n",
    "print(f\"Time taken to test the standard model: {end_time_s - start_time_s} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f58451-9562-457f-9f1d-ded60dcdad62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a127ac-d05a-47fa-b136-7723ada61917",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
